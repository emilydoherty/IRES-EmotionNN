{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion_Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, RandomFlip\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VREED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import VREED Dataset\n",
    "\n",
    "#Questionnaires \n",
    "VREEDpreQ = pd.read_excel('/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/VREED/Self-Reported Questionnaires/Participant Profile  Pre-Exposure Ratings.xlsx')\n",
    "VREEDpostQ=pd.read_excel('/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/VREED/Self-Reported Questionnaires/Post Exposure Ratings.xlsx')\n",
    "\n",
    "#Features (min, max, etc.)\n",
    "VREEDeye=pd.read_csv('/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/VREED/Eye Tracking Data/Eye Tracking Data (Features Extracted)/EyeTracking_FeaturesExtracted.csv')\n",
    "VREEDecg=pd.read_csv('/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/VREED/ECG-GSR Data/ECG-GSR (Features Extracted)/ECG_FeaturesExtracted.csv')\n",
    "VREEDgsr=pd.read_csv('/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/VREED/ECG-GSR Data/ECG-GSR (Features Extracted)/GSR_FeaturesExtracted.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CEAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import CEAP Data\n",
    "#Refer to ceap_example_notebook\n",
    "\n",
    "# Post-processed .csv\n",
    "CEAPpost=pd.read_csv('/Users/emilydoherty/Desktop/Data Jupyter Notebook_NEW/temp/ceap_example/Dataset_CEAP_postprocessed.csv')\n",
    "\n",
    "#Load CEAP Features .csv\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVReality \n",
    "this dataset will need to be filtered - hopefully use same filtering techniques as CEAP to extract features once that script is debugged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AV Reality Data\n",
    "AVRq=pd.read_excel('/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/AVReality/Data_new.xlsx',sheet_name=\"Sheet1\")\n",
    "AVRq.describe()\n",
    "AVRq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nature BVP Files \n",
    "path = '/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/AVReality/E4/Nature/BVP'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "csv_files=sorted(csv_files)\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "N_BVP=[]\n",
    "for file in csv_files:\n",
    "\tdf_list = (pd.read_csv(file))\n",
    "\tdf_list['filename']= os.path.basename(file)\n",
    "\tdf_list['cond']= 'Nature'\n",
    "\tN_BVP.append(df_list)\n",
    "\n",
    "N_BVP = pd.concat(N_BVP)\n",
    "\n",
    "N_BVP=N_BVP.drop(columns=['Event Id','Event Date','Event Duration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subway BVP Files \n",
    "path = '/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/AVReality/E4/Subway/BVP'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "csv_files=sorted(csv_files)\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "S_BVP=[]\n",
    "for file in csv_files:\n",
    "\tdf_list = (pd.read_csv(file))\n",
    "\tdf_list['filename']= os.path.basename(file)\n",
    "\tdf_list['cond']= 'Subway'\n",
    "\tS_BVP.append(df_list)\n",
    "\n",
    "S_BVP = pd.concat(S_BVP)\n",
    "\n",
    "S_BVP=S_BVP.drop(columns=['Event Id','Event Date','Event Duration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Blood Vol Pulse data\n",
    "All_BVP = [N_BVP, S_BVP]\n",
    "All_BVP= pd.concat(All_BVP)\n",
    "\n",
    "#Now apply filtering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nature GSR Files \n",
    "path = '/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/AVReality/E4/Nature/GSR'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "csv_files=sorted(csv_files)\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "N_GSR=[]\n",
    "for file in csv_files:\n",
    "\tdf_list = (pd.read_csv(file))\n",
    "\tdf_list['filename']= os.path.basename(file)\n",
    "\tdf_list['cond']= 'Nature'\n",
    "\tN_GSR.append(df_list)\n",
    "\n",
    "N_GSR = pd.concat(N_GSR)\n",
    "\n",
    "N_GSR=N_GSR.drop(columns=['Event Id','Event Date','Event Duration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subway GSR Files \n",
    "path = '/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/AVReality/E4/Subway/GSR'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "csv_files=sorted(csv_files)\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "S_GSR=[]\n",
    "for file in csv_files:\n",
    "\tdf_list = (pd.read_csv(file))\n",
    "\tdf_list['filename']= os.path.basename(file)\n",
    "\tdf_list['cond']= 'Subway'\n",
    "\tS_GSR.append(df_list)\n",
    "\n",
    "S_GSR = pd.concat(S_GSR)\n",
    "\n",
    "S_GSR=S_GSR.drop(columns=['Event Id','Event Date','Event Duration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All GSR data\n",
    "All_GSR = [N_GSR, S_GSR]\n",
    "All_GSR= pd.concat(All_GSR)\n",
    "\n",
    "#Now apply filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nature TMP Files \n",
    "path = '/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/AVReality/E4/Nature/TMP'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "csv_files=sorted(csv_files)\n",
    "\n",
    "# Read each CSV file into DataFrame\n",
    "# This creates a list of dataframes\n",
    "N_TMP=[]\n",
    "for file in csv_files:\n",
    "\tdf_list = (pd.read_csv(file))\n",
    "\tdf_list['filename']= os.path.basename(file)\n",
    "\tdf_list['cond']= 'Nature'\n",
    "\tN_TMP.append(df_list)\n",
    "\n",
    "N_TMP = pd.concat(N_TMP)\n",
    "\n",
    "N_TMP=N_TMP.drop(columns=['Event Id','Event Date','Event Duration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subway TMP Files \n",
    "path = '/Users/emilydoherty/Desktop/IRES/Emotion_Datasets/AVReality/E4/Subway/TMP'\n",
    "csv_files = glob.glob(path + \"/*.csv\")\n",
    "csv_files=sorted(csv_files)\n",
    "\n",
    "# Read each CSV file into DataFra\n",
    "# This creates a list of dataframes\n",
    "S_TMP=[]\n",
    "for file in csv_files:\n",
    "\tdf_list = (pd.read_csv(file))\n",
    "\tdf_list['filename']= os.path.basename(file)\n",
    "\tdf_list['cond']= 'Subway'\n",
    "\tS_TMP.append(df_list)\n",
    "\n",
    "S_TMP = pd.concat(S_TMP)\n",
    "\n",
    "S_TMP=S_TMP.drop(columns=['Event Id','Event Date','Event Duration'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All TMP data\n",
    "All_TMP = [N_TMP, S_TMP]\n",
    "All_TMP= pd.concat(All_TMP)\n",
    "\n",
    "#Now apply filtering \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
