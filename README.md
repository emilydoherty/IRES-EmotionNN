# IRES-EmotionNN
Project for constructing deep NN to classify emotion in real-time virtual enviornments. 

Datasets used:

VREED
https://www.kaggle.com/datasets/lumaatabbaa/vr-eyes-emotions-dataset-vreed
Tabbaa, L., Searle, R., Ang, C.S., Bafti, S.B., Hossain, M., Intarasirisawat, J., and Glancy, M. 2021. VREED: Virtual Reality Emotion Recognition Dataset using EyeTracking Physiological Measures. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies.![image](https://github.com/emilydoherty/IRES-EmotionNN/assets/88332460/3b74bff1-64fe-4423-846d-ee95f495af01)


CEAP-360VR
https://github.com/cwi-dis/CEAP-360VR-Dataset
T. Xue, A. El Ali, T. Zhang, G. Ding, and P. Cesar, "CEAP-360VR: A Continuous Physiological and Behavioral Emotion Annotation Dataset for 360° Videos," in IEEE Transactions on Multimedia, doi: 10.1109/TMM.2021.3124080.

VRFS 
https://github.com/vremotions/vrfs
Vatsal, Ritik, et al. "An Analysis of Physiological and Psychological Responses in Virtual Reality and Flat Screen Gaming." arXiv preprint arXiv:2306.09690 (2023).![image](https://github.com/emilydoherty/IRES-EmotionNN/assets/88332460/0f811767-e5aa-4816-b8b3-1485f7c93059)

AVR 
https://data.mendeley.com/datasets/y76vbw92y9/3
Ramirez-Lechuga, Sharon; Alonso-Valerdi, Luz Maria; Ibarra-Zarate, David I (2023), “Audiovirtual Reality to induce anger and happiness emotions: A physiological response (EEG, GSR, BVP and TMP) database”, Mendeley Data, V3, doi: 10.17632/y76vbw92y9.3![image](https://github.com/emilydoherty/IRES-EmotionNN/assets/88332460/b6cf4a05-e4e9-496b-b621-3f0c8c32b2c2)
